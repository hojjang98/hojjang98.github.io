---
title: "Research Review: UNICORN - Runtime Provenance-Based Detector for APT"
date: 2026-01-12
categories: ["paper-review"]
tags: ["SOC", "APT-Detection", "Provenance-Graphs", "Anomaly-Detection", "Graph-Sketching", "Evolutionary-Modeling", "UNICORN", "NDSS-2020", "SK-Shieldus-Rookies"]
series: ["SOC-Expertise-Deep-Dive"]
draft: false
summary: "TBê¸‰ ì‹œìŠ¤í…œ ë¡œê·¸ë¥¼ Graph Sketchingìœ¼ë¡œ ì••ì¶•í•˜ê³  ì‹œìŠ¤í…œì˜ ì‹œê³„ì—´ì  ë³€í™”ë¥¼ í•™ìŠµí•˜ëŠ” Evolutionary Modelingì„ í†µí•´, ì‹œê·¸ë‹ˆì²˜ ì—†ëŠ” Low-and-Slow APT ê³µê²©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íƒì§€í•˜ëŠ” í”„ë ˆì„ì›Œí¬ ì—°êµ¬"
---

# Research Review: UNICORN: Runtime Provenance-Based Detector for Advanced Persistent Threats
> **Analyzed Date:** 2026.01.08 - 2026.01.12  
> **Keywords:** APT Detection, Provenance Graphs, Anomaly Detection, Graph Sketching, Evolutionary Modeling  
> **Source:** Network and Distributed System Security Symposium (NDSS), 2020, pp. 1-18  
> **Link:** https://www.ndss-symposium.org/ndss-paper/unicorn-runtime-provenance-based-detector-for-advanced-persistent-threats/

---

## Why This Paper?

### ì„ ì • ë°°ê²½

**ì´ ë…¼ë¬¸ì„ ì„ íƒí•œ ì´ìœ :**  
- Beehiveì—ì„œ í•™ìŠµí•œ ë„¤íŠ¸ì›Œí¬ ë¡œê·¸ ë¶„ì„ì„ ë” ê¹Šì€ ë ˆë²¨ì¸ ì‹œìŠ¤í…œ í˜¸ì¶œ ìˆ˜ì¤€ provenance ê·¸ë˜í”„ë¡œ í™•ì¥
- SOCì˜ ìµœì¢… ë³´ìŠ¤ì¸ APT íƒì§€ - ê°€ì¥ íƒì§€í•˜ê¸° ì–´ë ¤ìš´ ê³µê²© ìœ í˜•ì„ ë‹¤ë£¸
- ë‹¨ìˆœ íƒì§€ë¥¼ ë„˜ì–´ long-running ì‹œìŠ¤í…œì—ì„œ stealthy ê³µê²©ì„ ì–´ë–»ê²Œ ì°¾ì•„ë‚´ëŠ”ì§€ì— ëŒ€í•œ ë°©ë²•ë¡ 
- ê·¸ë˜í”„ ê¸°ë°˜ ë¶„ì„ì€ í˜„ëŒ€ SOCì˜ í•µì‹¬ ê¸°ìˆ  - EDR, XDRì˜ ê¸°ë°˜ ì›ë¦¬

**í•™ìŠµ ëª©í‘œ:**  
1. Provenance ê·¸ë˜í”„ ê¸°ë°˜ APT íƒì§€ì˜ ì›ë¦¬ì™€ ì‹¤ë¬´ ì ìš© ë°©ë²• ì´í•´
2. Graph sketchingê³¼ evolutionary modelingì´ë¼ëŠ” ìƒˆë¡œìš´ ì ‘ê·¼ë²• í•™ìŠµ
3. Long-running APT ìº í˜ì¸ì„ íƒì§€í•˜ëŠ” SOC ì—­ëŸ‰ ê°•í™”

---

## Day 1 â€“ Research Context & Motivation
*(APTì˜ í•µì‹¬ íŠ¹ì„±ê³¼ íƒì§€ì˜ ê·¼ë³¸ì  ì–´ë ¤ì›€)*

### 1. ì—°êµ¬ ë°°ê²½: Low-and-Slow APT íƒì§€ì˜ í•œê³„

**APTì˜ ì¤‘ìš”ì„±**

APTëŠ” í˜„ëŒ€ ì‚¬ì´ë²„ ë³´ì•ˆì˜ ê°€ì¥ ì‹¬ê°í•œ ìœ„í˜‘ì´ë‹¤. ì¼ë°˜ ê³µê²©ê³¼ ë‹¬ë¦¬ APTëŠ”:
- Long timescale: ìˆ˜ê°œì›”ì—ì„œ ìˆ˜ë…„ì— ê±¸ì³ ì§„í–‰
- Stealthy: ì •ìƒ íŠ¸ë˜í”½ì— ì„ì—¬ ë“¤ì–´ê°€ íƒì§€ íšŒí”¼
- Zero-day exploits: ì‚¬ì „ ì‹œê·¸ë‹ˆì²˜ê°€ ì—†ì–´ ê¸°ì¡´ íƒì§€ ìš°íšŒ
- Targeted: íŠ¹ì • ì¡°ì§ì„ ì •êµí•˜ê²Œ ê³µê²©

**í˜„ì‹¤ì˜ í•œê³„**

ê¸°ì¡´ APT íƒì§€ ì‹œìŠ¤í…œë“¤ì˜ ë¬¸ì œì :

1. **Syscall trace ê¸°ë°˜ ì ‘ê·¼ë²•ì˜ í•œê³„**
   - Host-based IDSëŠ” ì§§ì€ ì‹œí€€ìŠ¤ë§Œ ë¶„ì„
   - Long-term context ë¶€ì¡± - APTì˜ ê¸´ ì‹œê°„ ìŠ¤íŒ¬ì„ í¬ì°© ëª» í•¨
   - ì •ìƒ í–‰ìœ„ì™€ êµ¬ë¶„ ì–´ë ¤ì›€

2. **Static modelì˜ í•œê³„**
   - Long-running ì‹œìŠ¤í…œì˜ ë™ì  í–‰ë™ ë³€í™” í¬ì°© ëª» í•¨
   - ì‹œìŠ¤í…œì´ ì§„í™”í•˜ë©´ false positive ê¸‰ì¦

3. **Dynamic modelì˜ í•œê³„**
   - Runtime ì¤‘ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì‹œ ê³µê²©ìê°€ ëª¨ë¸ì„ ì ì§„ì ìœ¼ë¡œ poisoning ê°€ëŠ¥
   - Low-and-slow ê³µê²©ì´ ì •ìƒìœ¼ë¡œ í•™ìŠµë¨

**ì—°êµ¬ ë¬¸ì œì˜ì‹**

ì–´ë–»ê²Œ long-running ì‹œìŠ¤í…œì—ì„œ low-and-slow APT ê³µê²©ì„ ì •í™•í•˜ê²Œ íƒì§€í•  ê²ƒì¸ê°€? íŠ¹íˆ:
- ì‹œê·¸ë‹ˆì²˜ ì—†ì´ zero-day íƒì§€
- ìˆ˜ê°œì›”ê°„ì˜ ì‹œìŠ¤í…œ ì‹¤í–‰ historyë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë¶„ì„
- ëª¨ë¸ poisoning ë°©ì§€í•˜ë©´ì„œë„ ì‹œìŠ¤í…œ ì§„í™” ëŒ€ì‘

### 2. í•µì‹¬ ê°œë…

| ê°œë… | ì •ì˜ | SOC ë§¥ë½ì—ì„œì˜ ì˜ë¯¸ |
|------|------|---------------------|
| **Provenance Graph** | ì‹œìŠ¤í…œ ì „ì²´ì˜ ì¸ê³¼ê´€ê³„ë¥¼ í‘œí˜„í•˜ëŠ” ë°©í–¥ ê·¸ë˜í”„. ë…¸ë“œëŠ” í”„ë¡œì„¸ìŠ¤/íŒŒì¼/ì†Œì¼“, ì—£ì§€ëŠ” ì‹œìŠ¤í…œ ì½œ ê´€ê³„ | ë‹¨ìˆœ ë¡œê·¸ ë¶„ì„ì„ ë„˜ì–´ ì „ì²´ attack chainì„ ì¶”ì . ê³µê²©ìê°€ ì–´ë–»ê²Œ lateral movement í–ˆëŠ”ì§€ ì‹œê°í™” |
| **Graph Sketching** | í° ê·¸ë˜í”„ë¥¼ ê³ ì • í¬ê¸°ì˜ ìš”ì•½ ë²¡í„°ë¡œ ì••ì¶•í•˜ëŠ” ê¸°ë²•. Weisfeiler-Lehman ì•Œê³ ë¦¬ì¦˜ ê¸°ë°˜ | ìˆ˜ì‹­ GB ê·œëª¨ì˜ audit logë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í¬ê¸°ë¡œ ì••ì¶•í•˜ì—¬ ì‹¤ì‹œê°„ ë¶„ì„ ê°€ëŠ¥ |
| **Evolutionary Modeling** | ì‹œìŠ¤í…œì˜ ì‹œê°„ì— ë”°ë¥¸ ìƒíƒœ ë³€í™”ë¥¼ ì—¬ëŸ¬ sub-modelë¡œ í•™ìŠµí•˜ëŠ” ë°©ë²• | ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸, ì‚¬ìš©ì í–‰ë™ ë³€í™” ë“±ì„ ë°˜ì˜í•˜ë©´ì„œë„ ê¸‰ê²©í•œ ì´ìƒì€ íƒì§€ |
| **Low-and-Slow Attack** | ìˆ˜ê°œì›”ì— ê±¸ì³ ì²œì²œíˆ ì§„í–‰ë˜ì–´ íƒì§€ë¥¼ íšŒí”¼í•˜ëŠ” APT ê³µê²© íŒ¨í„´ | ì¼ë°˜ IDSëŠ” burst trafficë§Œ íƒì§€. SOCëŠ” ì¥ê¸° baselineê³¼ ë¹„êµí•˜ì—¬ ë¯¸ì„¸í•œ drift ê°ì§€ í•„ìš” |

### 3. ì´ë¡ ì  ê¸°ë°˜: Provenance-Based Anomaly Detection

```
[Audit Logs] â†’ [Provenance Graph Construction]
                        â†“
            [Streaming Graph Histogram]
                        â†“
            [Graph Sketching (HistoSketch)]
                        â†“
            [Evolutionary Clustering Model]
                        â†“
            [Anomaly Detection via State Transition]
```

**í•µì‹¬ ì•„ì´ë””ì–´:**

UNICORNì€ 4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ APTë¥¼ íƒì§€í•œë‹¤:

1. **Provenance graph ìˆ˜ì§‘**: Linux Audit, Windows ETW ë“±ì—ì„œ ì‹œìŠ¤í…œ ì „ì²´ì˜ ì¸ê³¼ê´€ê³„ ê·¸ë˜í”„ ìƒì„±
2. **Streaming histogram**: R-hop neighborhoodë¥¼ íƒìƒ‰í•˜ì—¬ ê° vertex ì£¼ë³€ì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ histogramìœ¼ë¡œ ìš”ì•½
3. **Graph sketching**: Histogramì„ ê³ ì • í¬ê¸° ë²¡í„°ë¡œ ì••ì¶• (HistoSketch) - gradually forgetting ê¸°ë²•ìœ¼ë¡œ ìµœê·¼ í™œë™ì— ê°€ì¤‘ì¹˜
4. **Evolutionary model**: Training ì¤‘ ìƒì„±ëœ ì—¬ëŸ¬ ì‹œì ì˜ sketchë¥¼ clusteringí•˜ì—¬ ì‹œìŠ¤í…œì˜ ì •ìƒ ìƒíƒœ ì „ì´ íŒ¨í„´ í•™ìŠµ

Detection ì‹œì—ëŠ” ìƒˆë¡œìš´ sketchê°€ í•™ìŠµí•œ clusterì— fití•˜ëŠ”ì§€, ê·¸ë¦¬ê³  state transitionì´ validí•œì§€ ê²€ì‚¬í•œë‹¤.

### 4. ì—°êµ¬ì˜ í•µì‹¬ ê¸°ì—¬

**í•™ìˆ ì  ê¸°ì—¬:**

1. **Graph sketching ê¸°ë°˜ APT íƒì§€ í”„ë ˆì„ì›Œí¬**
   - Long-running ì‹œìŠ¤í…œì˜ ì „ì²´ historyë¥¼ ê³ ì • í¬ê¸° ë°ì´í„° êµ¬ì¡°ë¡œ ìš”ì•½
   - Weisfeiler-Lehman ì•Œê³ ë¦¬ì¦˜ì„ streaming í™˜ê²½ì— ì ìš©
   - Time-weighted histogramìœ¼ë¡œ ì¸ê³¼ê´€ê³„ì™€ ì‹œê°„ locality ë™ì‹œ ë°˜ì˜

2. **Evolutionary modeling**
   - ë‹¨ì¼ training traceì—ì„œ ì‹œê°„ì— ë”°ë¥¸ ì—¬ëŸ¬ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ í•™ìŠµ
   - Concept drift ëŒ€ì‘í•˜ë©´ì„œë„ model poisoning ë°©ì§€
   - State transition ê¸°ë°˜ anomaly detection

3. **APT íŠ¹ì„±ì— íŠ¹í™”ëœ 4ê°€ì§€ ì„¤ê³„ ì›ì¹™**
   - L1: Rich historical context - R-hop graph exploration
   - L2: Contextualized analysis - Causality-based graph neighborhood
   - L3: Robust long-term modeling - Evolutionary model without runtime update
   - L4: Space efficiency - In-memory histogram, no full graph storage

**SOC ì‹¤ë¬´ ê¸°ì—¬:**

1. **ì‹œê·¸ë‹ˆì²˜ ì—†ëŠ” Zero-day APT íƒì§€**
   - Anomaly-based ì ‘ê·¼ìœ¼ë¡œ unseen attack pattern íƒì§€
   - DARPA datasetì—ì„œ ëª¨ë“  APT ê³µê²© íƒì§€ ì„±ê³µ

2. **ê¸°ì¡´ SOTA ëŒ€ë¹„ ì„±ëŠ¥ í–¥ìƒ**
   - StreamSpot ëŒ€ë¹„ precision 24% í–¥ìƒ, accuracy 30% í–¥ìƒ
   - False positive ëŒ€í­ ê°ì†Œ

3. **Real-time ì‹¤ìš©ì„±**
   - í‰ê·  CPU ì‚¬ìš©ë¥  <5%
   - Memory footprint: ~200MB (TB ê·œëª¨ audit log ì²˜ë¦¬)
   - Processing speed: í‰ê·  11,000 events/second

### 5. SOC ê´€ì  ì¸ì‚¬ì´íŠ¸

**ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±:**

UNICORNì€ EDR/XDRì˜ ì°¨ì„¸ëŒ€ ë°±ì—”ë“œ ì—”ì§„ìœ¼ë¡œ í™œìš© ê°€ëŠ¥í•˜ë‹¤. í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ EDRì€ rule-basedì´ì§€ë§Œ, UNICORNì˜ provenance ê¸°ë°˜ anomaly detectionì€:
- Supply chain attack ê°™ì€ ì‹ ì¢… APT íƒì§€
- Insider threatì˜ long-term behavior ì¶”ì 
- Threat hunting ì‹œ ê³µê²© ì „ì²´ kill chain ì¬êµ¬ì„±

**ê¸°ì¡´ í•™ìŠµê³¼ì˜ ì—°ê²°:**

- **DeepLogì™€ì˜ ë¹„êµ**: DeepLogëŠ” ë‹¨ì¼ ì‹œìŠ¤í…œì˜ log sequence anomaly. UNICORNì€ ì „ì²´ ì‹œìŠ¤í…œì˜ graph structure anomaly
- **Lou et al.ê³¼ì˜ ë¹„êµ**: Invariants miningì€ rule-based. UNICORNì€ clustering-based unsupervised learning
- **Beehiveì™€ì˜ ë¹„êµ**: BeehiveëŠ” network-level workflow. UNICORNì€ system-level provenance graph

Progression: Log sequence â†’ Network workflow â†’ System provenance graph

**í˜„ì‹¤ì  ê³ ë ¤ì‚¬í•­:**

1. **Ground truth ë¬¸ì œ**: APTëŠ” ì‹¤ì œ í™˜ê²½ì—ì„œ labelì´ ë¶ˆëª…í™•. ì–´ë–»ê²Œ ëª¨ë¸ í‰ê°€?
2. **Parameter tuning**: R, |S|, Î» ë“± í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ê° í™˜ê²½ì— ë§ê²Œ ì¡°ì • í•„ìš”
3. **Provenance overhead**: CamFlow ê°™ì€ whole-system provenance ìˆ˜ì§‘ì˜ ì„±ëŠ¥ ì˜¤ë²„í—¤ë“œ
4. **False positive ê´€ë¦¬**: ì •ìƒ ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ë„ anomalyë¡œ íƒì§€ ê°€ëŠ¥ - ì •ê¸°ì  ì¬í•™ìŠµ í•„ìš”

---

## Day 2 â€“ Research Model, Hypotheses, and Methodology
*(Graph Sketchingê³¼ Evolutionary Modelingì˜ ì„¤ê³„)*

### 1. ì—°êµ¬ ëª¨ë¸ ê°œìš”

```
[Training Phase]
Streaming Provenance Graph
    â†“
[1] Incremental Histogram Construction (R-hop exploration)
    â†“
[2] Periodic Sketching (gradually forgetting with Î»)
    â†“
[3] Sketch Collection over time: S(tâ‚), S(tâ‚‚), ..., S(tâ‚™)
    â†“
[4] Evolutionary Clustering: Group sketches into clusters
    â†“
[5] State Transition Model: Track cluster sequences

[Detection Phase]
New Streaming Graph â†’ Histogram â†’ Sketch â†’ S(t_new)
    â†“
Check: (1) Does S(t_new) fit any cluster?
       (2) Is state transition valid?
    â†“
[Anomaly if either fails]
```

**ì„¤ê³„ ì² í•™:**

UNICORNì€ APTì˜ 4ê°€ì§€ íŠ¹ì„±ì— ëŒ€ì‘í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤:

1. **Long-running**: Graph sketchingìœ¼ë¡œ ìˆ˜ê°œì›” historyë¥¼ ê³ ì • í¬ê¸°ë¡œ ìš”ì•½
2. **Stealthy**: Evolutionary modelingìœ¼ë¡œ ë¯¸ì„¸í•œ deviation íƒì§€
3. **Zero-day**: Unsupervised anomaly detection - ì‚¬ì „ ì‹œê·¸ë‹ˆì²˜ ë¶ˆí•„ìš”
4. **Contextualized**: R-hop explorationìœ¼ë¡œ causal relationship í¬í•¨

### 2. ì—°êµ¬ ê°€ì„¤ (í•µì‹¬ ê°€ì •)

| ê°€ì • | ë‚´ìš© | ê·¼ê±° |
|------|------|------|
| **A1: Provenance graphs capture APT** | ì‹œìŠ¤í…œ ì „ì²´ì˜ ì¸ê³¼ê´€ê³„ ê·¸ë˜í”„ëŠ” APTì˜ ì „ì²´ attack chainì„ í¬í•¨í•œë‹¤ | APTëŠ” ì‹œìŠ¤í…œ ì½œì„ í†µí•´ ì‹¤í–‰ë˜ë©°, provenanceëŠ” ëª¨ë“  ì‹œìŠ¤í…œ ì½œ ê´€ê³„ë¥¼ ê¸°ë¡ |
| **A2: APTëŠ” ì •ìƒê³¼ êµ¬ì¡°ì ìœ¼ë¡œ ë‹¤ë¥´ë‹¤** | APTì˜ provenance graph êµ¬ì¡°ëŠ” ì •ìƒ ì‹œìŠ¤í…œ í–‰ë™ê³¼ í†µê³„ì ìœ¼ë¡œ êµ¬ë¶„ ê°€ëŠ¥í•˜ë‹¤ | ê³µê²©ìì˜ reconnaissance, exploitation, exfiltrationì€ ì •ìƒ workflowì™€ ë‹¤ë¥¸ graph pattern ìƒì„± |
| **A3: Sketch preserves anomaly signal** | Graphë¥¼ sketchë¡œ ì••ì¶•í•´ë„ anomaly detectionì— í•„ìš”í•œ ì •ë³´ëŠ” ë³´ì¡´ëœë‹¤ | Weisfeiler-Lehman ê¸°ë°˜ histogramì€ graph isomorphism testì— ì¤€í•˜ëŠ” êµ¬ë³„ë ¥ |
| **A4: System evolution is gradual** | ì •ìƒ ì‹œìŠ¤í…œì˜ í–‰ë™ ë³€í™”ëŠ” ì ì§„ì ì´ë©°, ê¸‰ê²©í•œ ë³€í™”ëŠ” anomalyë‹¤ | ì†Œí”„íŠ¸ì›¨ì–´ ì—…ë°ì´íŠ¸, ì‚¬ìš©ì ìŠµê´€ ë³€í™”ëŠ” ì„œì„œíˆ ì§„í–‰ë˜ë©°, APT ê³µê²©ì€ ê°‘ì‘ìŠ¤ëŸ½ê²Œ ë‚˜íƒ€ë‚¨ |
| **A5: No adversarial model poisoning** | Kernelê³¼ provenance ìˆ˜ì§‘ ì‹œìŠ¤í…œì€ ì‹ ë¢°í•  ìˆ˜ ìˆë‹¤ | Attested boot, LSM integrityë¡œ ë³´ì¥. ë˜ëŠ” off-host analysis |

### 3. ì—°êµ¬ ë°©ë²•ë¡ 

#### A. ë°ì´í„° ìˆ˜ì§‘

**ë°ì´í„° ì†ŒìŠ¤:**

| ì†ŒìŠ¤ | ìˆ˜ì§‘ ì •ë³´ | ìš©ë„ |
|------|-----------|------|
| **Linux Audit** | syscall trace (open, read, write, fork, exec, connect, etc.) | í”„ë¡œì„¸ìŠ¤-íŒŒì¼-ë„¤íŠ¸ì›Œí¬ ê°„ ì¸ê³¼ê´€ê³„ ê·¸ë˜í”„ ìƒì„± |
| **CamFlow** | Kernel-level provenance capture | Controlled lab í™˜ê²½ supply chain attack ì‹œë‚˜ë¦¬ì˜¤ |
| **DARPA TC Datasets** | CADETS, ClearScope, THEIA from 3 OS platforms | Real APT campaign í‰ê°€ |

**ë°ì´í„° ê·œëª¨:**

- **DARPA datasets**: 2ì£¼ê°„ adversarial engagement
  - CADETS (FreeBSD): 90.9M events, 451 GB raw data
  - ClearScope (Linux): 31.8M events, 164 GB
  - THEIA (Linux): 78.5M events, 312 GB
- **Supply Chain scenarios**: 125 benign + 25 attack graphs per scenario
- APTëŠ” ì „ì²´ audit dataì˜ 0.001% ë¯¸ë§Œ - extreme imbalance

**ë°ì´í„° íŠ¹ì„± ë° ë¬¸ì œì :**

- **Heterogeneity**: ë‹¤ì–‘í•œ OS, ë‹¤ì–‘í•œ provenance capture ì‹œìŠ¤í…œ
- **High volume**: TB ë‹¨ìœ„ audit log - ë©”ëª¨ë¦¬ì— ì˜¬ë¦´ ìˆ˜ ì—†ìŒ
- **Temporal locality**: ìµœê·¼ í–‰ë™ì´ ë” ì¤‘ìš”í•˜ì§€ë§Œ, ì˜¤ë˜ëœ ì¸ê³¼ê´€ê³„ë„ ìœ ì§€ í•„ìš”
- **Partial ordering**: Provenance edge ë„ì°© ìˆœì„œê°€ ì‹¤ì œ ë°œìƒ ìˆœì„œì™€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ

#### B. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜/ê¸°ë²•

**[1] Incremental Histogram Construction**

ëª©ì : Streaming provenance graphì˜ êµ¬ì¡°ì  íŠ¹ì§•ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì¶”ì¶œ

ë°©ë²•:
```
1. ì´ˆê¸°í™”: ê° vertex vì— label l(v) í• ë‹¹ (í”„ë¡œì„¸ìŠ¤, íŒŒì¼, ì†Œì¼“ ë“±)
2. For iteration r = 0 to R:
   a. ê° vertex vì˜ r-hop neighborhood ìˆ˜ì§‘
   b. Multiset M(v) = {l(u) | uëŠ” vì˜ r-hop neighbor}
   c. Hash M(v) â†’ new label l'(v)
   d. Histogram H[l'(v)] += weight(v, r)
3. Weight function:
   - Temporal locality: w(t) = Î»^(-Î”t) (gradually forgetting)
   - Causal dependency: w(path_length) = 1 (no discount for causal edges)
```

í•µì‹¬ ì•„ì´ë””ì–´:
- Weisfeiler-Lehman ì•Œê³ ë¦¬ì¦˜ì˜ streaming ë²„ì „
- R-hop explorationìœ¼ë¡œ local graph structureë¥¼ labelë¡œ ì¸ì½”ë”©
- Gradually forgetting: ì‹œê°„ ê²½ê³¼ì— ë”°ë¼ weight decay, ë‹¨ ì¸ê³¼ê´€ê³„ëŠ” ìœ ì§€

**[2] Graph Sketching (HistoSketch)**

ëª©ì : ë¬´í•œíˆ ì¦ê°€í•˜ëŠ” histogramì„ ê³ ì • í¬ê¸° |S|ë¡œ ì••ì¶•

ë°©ë²•:
```
1. Top-|S| frequent histogram elements ì„ íƒ
2. Normalize: Jaccard similarity ê³„ì‚°ì„ ìœ„í•´ í™•ë¥  ë¶„í¬ë¡œ ë³€í™˜
3. Sketch S(t) = {(label, frequency) | top |S| elements}
4. Constant time update:
   - New edge ë„ì°© ì‹œ affected verticesë§Œ ì—…ë°ì´íŠ¸
   - Batch processingìœ¼ë¡œ overhead ê°ì†Œ
```

Trade-off:
- |S| í¬ë©´: ë” ë§ì€ ì •ë³´, ë” ë†’ì€ ê³„ì‚° ë¹„ìš©
- |S| ì‘ìœ¼ë©´: ì •ë³´ ì†ì‹¤, ë¹ ë¥¸ ê³„ì‚°

ì‹¤í—˜ì—ì„œëŠ” |S| = 2000ì´ ì ì ˆí•¨ì„ í™•ì¸.

**[3] Evolutionary Clustering**

ëª©ì : Training executionì˜ ì—¬ëŸ¬ ì‹œì ì—ì„œ ìƒì„±ëœ sketchë¥¼ clusteringí•˜ì—¬ ì‹œìŠ¤í…œì˜ ì •ìƒ ìƒíƒœ í•™ìŠµ

ë°©ë²•:
```
1. Training ì¤‘ Tê°œì˜ sketch ìƒì„±: {S(tâ‚), S(tâ‚‚), ..., S(tâ‚œ)}
2. Sketch ê°„ Jaccard distance ê³„ì‚°:
   d(S_i, S_j) = 1 - |S_i âˆ© S_j| / |S_i âˆª S_j|
3. Hierarchical clustering with distance threshold Î¸
4. ê° cluster C_këŠ” ì‹œìŠ¤í…œì˜ í•œ "meta-state"ë¥¼ í‘œí˜„
5. Evolution E = ordered sequence of cluster indices
   ì˜ˆ: [Câ‚, Câ‚, Câ‚‚, Câ‚ƒ, Câ‚‚, Câ‚ƒ, Câ‚ƒ, ...]
```

Evolutionary modelì˜ ì¥ì :
- Single training traceì—ì„œ multiple system states í•™ìŠµ
- Concept drift ìë™ ë°˜ì˜ (ì‹œìŠ¤í…œì´ ì§„í™”í•˜ë©´ ìƒˆ cluster ìƒì„±)
- Model poisoning ë°©ì§€ (training í›„ model freeze)

#### C. í”¼ì²˜/ë³€ìˆ˜ ì„¤ê³„

**í”¼ì²˜ ì„¤ê³„ ì›ì¹™:**

Graphì˜ local structureë¥¼ labelë¡œ ì¸ì½”ë”©. ê° labelì€ íŠ¹ì • r-hop neighborhood patternì„ ëŒ€í‘œ.

**ì£¼ìš” í”¼ì²˜:**

| í”¼ì²˜ | ì„¤ëª… | ê³„ì‚° ë°©ë²• |
|------|------|-----------|
| **Vertex label** | ë…¸ë“œ ìœ í˜• (process, file, socket, pipe) | Provenance graphì˜ node type |
| **Edge label** | Relation ìœ í˜• (read, write, exec, connect) | System call type |
| **R-hop subgraph hash** | r-hop neighborhoodì˜ êµ¬ì¡°ì  fingerprint | Weisfeiler-Lehman hash |
| **Histogram element** | (hash, count) pair | ê° subgraph patternì˜ ì¶œí˜„ ë¹ˆë„ |
| **Sketch vector** | Top-|S| histogram elements | Normalized frequency distribution |

íŠ¹ì§•:
- No manual feature engineering - ì•Œê³ ë¦¬ì¦˜ì´ ìë™ìœ¼ë¡œ meaningful pattern ì¶”ì¶œ
- Heterogeneous graph labels ì§€ì› - ë‹¤ì–‘í•œ entityì™€ relation type
- Temporal weighting - gradually forgettingìœ¼ë¡œ recency ë°˜ì˜

#### D. í‰ê°€ ë°©ë²•

**í‰ê°€ ì§€í‘œ:**

- **Precision**: TP / (TP + FP) - íƒì§€í•œ ê²ƒ ì¤‘ ì‹¤ì œ ê³µê²© ë¹„ìœ¨
- **Recall**: TP / (TP + FN) - ì‹¤ì œ ê³µê²© ì¤‘ íƒì§€í•œ ë¹„ìœ¨
- **Accuracy**: (TP + TN) / (TP + TN + FP + FN)
- **F1-Score**: 2 Ã— (Precision Ã— Recall) / (Precision + Recall)

**ë¹„êµ ëŒ€ìƒ:**

- **StreamSpot**: ê¸°ì¡´ SOTA graph-based anomaly detector
- **Holmes & Poirot**: Rule-based provenance analysis (DARPA datasetì—ì„œë§Œ)
- **Baseline configuration**: R=1 (no graph exploration)

**Cross-validation:**

- DARPA: 90% training, 10% testing
- Supply Chain: 5-fold cross-validation (100 benign training, 25 benign + 25 attack testing)

### 4. SOC ê´€ì  ì¸ì‚¬ì´íŠ¸

**ë°©ë²•ë¡ ì˜ ì‹¤ë¬´ ì ìš©ì„±:**

ì¥ì :
- **Unsupervised learning**: SOCì— labelëœ APT ë°ì´í„°ê°€ ì—†ì–´ë„ ì‘ë™
- **Real-time streaming**: Batch processing ë¶ˆí•„ìš”, ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥
- **Explainability**: ì–´ë–¤ graph structureê°€ anomalyì¸ì§€ histogram elementë¡œ ì„¤ëª… ê°€ëŠ¥

í•œê³„:
- **Parameter tuning í•„ìš”**: R, |S|, Î», Î¸ë¥¼ ê° í™˜ê²½ì— ë§ê²Œ ì¡°ì •
- **Initial training í•„ìš”**: Clean baseline í™•ë³´ - ì´ë¯¸ ì¹¨íˆ¬ëœ ìƒíƒœë¼ë©´?
- **Concept drift ëŒ€ì‘**: ì£¼ê¸°ì  ì¬í•™ìŠµ í•„ìš” (ì–¼ë§ˆë‚˜ ìì£¼?)

**ê¸°ì¡´ SOC íˆ´ê³¼ì˜ ì°¨ë³„ì :**

| ë„êµ¬/ë°©ë²• | íƒì§€ ë°©ì‹ | ê°•ì  | ì•½ì  |
|-----------|-----------|------|------|
| **Traditional SIEM** | Rule/signature-based | ì•Œë ¤ì§„ ê³µê²© í™•ì‹¤íˆ íƒì§€, ì„¤ëª… ì‰¬ì›€ | Zero-day ëª» ì¡ìŒ, rule ìœ ì§€ë³´ìˆ˜ ë¹„ìš© |
| **UEBA** | User behavior analytics | Insider threat íƒì§€ | User-levelë§Œ ë³´ê³  system-level ì¸ê³¼ê´€ê³„ ë¶€ì¡± |
| **EDR (Rule-based)** | IoC matching | ë¹ ë¦„, FP ì ìŒ | APTëŠ” IoC ì—†ì´ ì§„í–‰ |
| **UNICORN** | Provenance graph anomaly | Zero-day APT íƒì§€, ì „ì²´ attack chain ì¶”ì  | Parameter tuning í•„ìš”, ì´ˆê¸° í•™ìŠµ í•„ìš” |

**SOC Workflow í†µí•© ì „ëµ:**

```
[1] Endpoint: CamFlow/Auditd â†’ Provenance stream
       â†“
[2] UNICORN Backend: Real-time graph sketching & anomaly detection
       â†“
[3] Alert Generation: Anomalous sketch â†’ High-risk process/file ì¶”ì¶œ
       â†“
[4] SIEM Integration: Enrich alert with threat intelligence
       â†“
[5] SOC Analyst: Graph visualizationìœ¼ë¡œ attack chain í™•ì¸
       â†“
[6] Response: Kill process, isolate host, forensic collection
```

UNICORNì„ SIEMì˜ advanced detection engineìœ¼ë¡œ í†µí•©í•˜ë©´:
- L1: SIEM ruleë¡œ 1ì°¨ í•„í„°ë§
- L2: UNICORN anomaly detectionìœ¼ë¡œ APT í›„ë³´ ì¶”ì¶œ
- L3: Analystê°€ graph ì‹œê°í™”ë¡œ ìµœì¢… íŒë‹¨

---

## Day 3 â€“ Empirical Results and Hypothesis Testing
*(UNICORNì˜ APT íƒì§€ ì„±ëŠ¥ ê²€ì¦)*

### 1. í‰ê°€ í™˜ê²½

**ì‹¤í—˜ ì„¤ì •:**

1. **StreamSpot Benchmark**
   - ë°ì´í„°: 600 provenance graphs (5 scenario types)
   - í™˜ê²½: Controlled simulation

2. **DARPA TC Engagement 3**
   - ê¸°ê°„: 2ì£¼ê°„ red team vs blue team engagement
   - ë°ì´í„°: 3ê°œ OS í”Œë«í¼ (FreeBSD, Linux, Linux)
   - í™˜ê²½: Realistic enterprise network
   - íŠ¹ì§•: APT ê³µê²© ë¹„ìœ¨ <0.001% of audit data

3. **Supply Chain Attack**
   - í™˜ê²½: CamFlow on Ubuntu 16.04
   - ë°ì´í„°: 2ê°œ ì‹œë‚˜ë¦¬ì˜¤ (SC-1, SC-2) Ã— 125 benign + 25 attack
   - íŠ¹ì§•: Attackers know system a priori (harder to detect)

**ì‹¤í—˜ ì „ëµ:**

- **Q1**: Can UNICORN detect APTs accurately?
- **Q2**: How important is R-hop exploration?
- **Q3**: Does Î» decay (gradually forgetting) improve detection?
- **Q4**: Evolutionary vs static clustering?
- **Q5**: Real-time capability?
- **Q6**: CPU/memory overhead?

### 2. ì£¼ìš” ë°œê²¬

**ì „ì²´ ê²°ê³¼ ìš”ì•½:**

| Dataset | Precision | Recall | Accuracy | F1-Score |
|---------|-----------|--------|----------|----------|
| **StreamSpot (R=1)** | ~0.94 | ~0.99 | ~0.97 | ~0.96 |
| **StreamSpot (R=3)** | **0.99** | **1.00** | **0.99** | **0.99** |
| **DARPA-CADETS** | 1.00 | 1.00 | N/A | 1.00 |
| **DARPA-ClearScope** | 1.00 | 1.00 | N/A | 1.00 |
| **DARPA-THEIA** | 1.00 | 1.00 | N/A | 1.00 |
| **SC-1** | 0.96 | 1.00 | 0.98 | 0.98 |
| **SC-2** | 0.91 | 1.00 | 0.95 | 0.95 |

**ê¸°ì¡´ ë°©ë²•ê³¼ì˜ ë¹„êµ:**

| Method | Precision | Accuracy | Improvement |
|--------|-----------|----------|-------------|
| **StreamSpot (baseline)** | ~0.75 | ~0.69 | - |
| **UNICORN (R=3)** | 0.99 | 0.99 | +32% precision, +43% accuracy |

UNICORNì€ StreamSpot ëŒ€ë¹„:
- **Precision 24% í–¥ìƒ** (0.75 â†’ 0.99)
- **Accuracy 30% í–¥ìƒ** (0.69 â†’ 0.99)
- R=3 (graph exploration)ì´ R=1ë³´ë‹¤ í¬ê²Œ ìš°ìˆ˜

### 3. ìƒì„¸ ë¶„ì„

#### A. DARPA Real APT Detection

**ê´€ì°°:**

UNICORNì€ 3ê°œ í”Œë«í¼ ëª¨ë‘ì—ì„œ:
- **Precision 1.00**: False positive 0ê°œ
- **Recall 1.00**: ëª¨ë“  APT ê³µê²© íƒì§€

**í•´ì„:**

DARPA ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ APTê°€ ì˜ íƒì§€ëœ ì´ìœ :
1. **Reconnaissance phaseê°€ ëª…í™•**: ê³µê²©ìê°€ vulnerability ì°¾ëŠ” ê³¼ì •ì´ traceì— ë‚˜íƒ€ë‚¨
2. **Unusual system call sequence**: Exploitationì€ ì •ìƒ user behaviorì™€ ëª…í™•íˆ ë‹¤ë¦„
3. **Causal dependency ì¶”ì **: Data exfiltrationì˜ ì „ì²´ provenance chain í¬ì°©

Holmesì™€ Poirot (rule-based)ë„ ëª¨ë“  ê³µê²© íƒì§€í–ˆì§€ë§Œ:
- ì‚¬ì „ expert knowledge í•„ìš”
- New attack vectorì—ëŠ” ëŒ€ì‘ ëª» í•¨
- UNICORNì€ unsupervisedë¡œ ë™ì¼í•œ ì„±ëŠ¥

**ì‹¤ë¬´ ì‹œì‚¬ì :**

DARPA ìˆ˜ì¤€ì˜ APTëŠ” SOCì—ì„œ ì¶©ë¶„íˆ íƒì§€ ê°€ëŠ¥í•˜ë‹¤. ë‹¨, ì¡°ê±´:
- Clean training data (attacker-free baseline)
- Sufficient context (Râ‰¥3 hop exploration)
- Proper tuning (|S|=2000, Î» appropriate)

#### B. Supply Chain Attack Scenarios

**ì‹œë‚˜ë¦¬ì˜¤ ì„¤ê³„:**

**SC-1: Simulated software update**
- Benign: User downloads Firefox updates, installs normally
- Attack: Trojanized Firefox installer executes backdoor
- íŠ¹ì§•: Installer behavior is similar to benign

**SC-2: Document processing**
- Benign: User opens PDFs, runs office applications
- Attack: Malicious PDF exploits viewer, drops payload
- íŠ¹ì§•: Initial trigger (open PDF) is benign

**ê²°ê³¼:**

| Scenario | Precision | Recall | False Positives |
|----------|-----------|--------|-----------------|
| SC-1 | 0.96 | 1.00 | 1/25 |
| SC-2 | 0.91 | 1.00 | 2-3/25 |

**Why lower than DARPA?**

Supply chain ì‹œë‚˜ë¦¬ì˜¤ê°€ ë” ì–´ë ¤ìš´ ì´ìœ :
1. **No reconnaissance phase**: Attacker knows system, ì§ì ‘ exploit
2. **Initial benign trigger**: Software updateë‚˜ PDF openì€ ì •ìƒ í–‰ë™
3. **Gradual payload execution**: Backdoorê°€ ì²œì²œíˆ ì‹¤í–‰ë˜ì–´ gradually forgettingì— ê±¸ë¦´ ìˆ˜ ìˆìŒ

**ì‹¤ë¬´ ì‹œì‚¬ì :**

Supply chain attack íƒì§€ë¥¼ ìœ„í•´ì„œëŠ”:
- **Contextual analysis ê°•í™”**: Rì„ 3 ì´ìƒìœ¼ë¡œ
- **Evolutionary model í™•ì¥**: ë” ë§ì€ training executionìœ¼ë¡œ edge case í¬í•¨
- **Hybrid approach**: UNICORN + rule-based for known supply chain patterns

#### C. Graph Analysis Importance

**ì‹¤í—˜: R-hop ì˜í–¥**

SC-1 datasetìœ¼ë¡œ Rì„ ë³€í™”ì‹œí‚¤ë©° ì„±ëŠ¥ ì¸¡ì •:

| R (hop count) | Precision | Recall | F1 |
|---------------|-----------|--------|----|
| R = 1 | 0.89 | 0.96 | 0.92 |
| R = 3 (baseline) | 0.96 | 1.00 | 0.98 |
| R = 5 | 0.98 | 1.00 | 0.99 |
| R = 7 | 0.98 | 1.00 | 0.99 |

**í•´ì„:**

R-hop explorationì´ ì¤‘ìš”í•œ ì´ìœ :
- **Causal context**: R=1ì€ ì§ì ‘ ì—°ê²°ë§Œ, R=3ì€ multi-step attack chain í¬ì°©
- **Disambiguation**: ë™ì¼í•œ local patternì´ë¼ë„ wider contextë¡œ benign vs attack êµ¬ë¶„

ì˜ˆì‹œ:
```
R=1: process A â†’ read file X (ì •ìƒ? ê³µê²©?)
R=3: process A â†’ read file X â† written by process B â† spawned by suspicious downloader
â†’ ëª…í™•íˆ attack chain
```

**ì‹¤ë¬´ ì ìš©:**

SOCì—ì„œ R ì„ íƒ:
- **R=1**: ë¹ ë¥´ì§€ë§Œ ë¶€ì •í™• â†’ ì‹¤ì‹œê°„ 1ì°¨ í•„í„°
- **R=3**: ê· í˜•ì  â†’ ëŒ€ë¶€ë¶„ì˜ APT íƒì§€
- **R=5+**: ë†’ì€ ì •í™•ë„ â†’ Threat hunting, forensic analysis

#### D. Evolutionary Modeling vs Static Clustering

**ì‹¤í—˜:**

| Approach | Description | Precision | Recall |
|----------|-------------|-----------|--------|
| **Static clustering** | Single clustering on all training sketches | 0.88 | 0.96 |
| **Evolutionary (UNICORN)** | Time-ordered clustering | 0.96 | 1.00 |

**Why evolutionary better?**

1. **Concept drift ë°˜ì˜**: Staticì€ ì‹œìŠ¤í…œ ì´ˆê¸°ì™€ ë§ê¸°ë¥¼ ë™ì¼í•˜ê²Œ ì·¨ê¸‰, EvolutionaryëŠ” ì§„í™” ê³¼ì •ì„ state transitionìœ¼ë¡œ í•™ìŠµ

2. **False positive ê°ì†Œ**: Staticì€ ì •ìƒ ì—…ë°ì´íŠ¸ê°€ anomalyë¡œ íƒì§€ë¨, EvolutionaryëŠ” ì ì§„ì  ë³€í™”ë¥¼ valid state transitionìœ¼ë¡œ ì¸ì •

3. **Context-aware detection**: Staticì€ ê° sketchë¥¼ ë…ë¦½ì ìœ¼ë¡œ í‰ê°€, EvolutionaryëŠ” ì´ì „ ìƒíƒœë¡œë¶€í„°ì˜ transition ìœ íš¨ì„± ê²€ì‚¬

**ì‹¤ë¬´ ì ìš©:**

Long-running SOC í™˜ê²½ì—ì„œ ì‹œìŠ¤í…œì€ ëŠì„ì—†ì´ ë³€í™” (íŒ¨ì¹˜, ì—…ë°ì´íŠ¸, user behavior drift). Static modelì€ ë¹ ë¥´ê²Œ obsolete. Evolutionary modelì€ ë³€í™”ë¥¼ í¡ìˆ˜í•˜ë©´ì„œë„ ê¸‰ê²©í•œ anomaly íƒì§€.

### 4. ì„±ëŠ¥ íš¨ìœ¨ì„±

**Processing Speed:**

| Dataset | Events/sec | Latency |
|---------|------------|---------|
| SC-1 | 11,000 | <100ms |
| SC-2 | 10,500 | <100ms |
| DARPA-CADETS | 9,800 | <150ms |

â†’ Real-time monitoringì— ì¶©ë¶„

**Resource Usage:**

| Metric | Value |
|--------|-------|
| Average CPU | <5% |
| Peak CPU | 12% |
| Memory footprint | ~200MB |
| Raw data size | TB scale |

â†’ Commodity hardwareì—ì„œ ì‹¤í–‰ ê°€ëŠ¥

### 5. SOC ê´€ì  ì‹¤ë¬´ ì¸ì‚¬ì´íŠ¸

**íƒì§€ ì¸¡ë©´:**

ì„±ê³µ ì‚¬ë¡€: Multi-stage attacks, data exfiltration, credential dumping, backdoor installation

ê°œì„  í•„ìš”: Fileless attacks (memory-only execution), living-off-the-land (PowerShell, wmic), low-volume exfiltration

**ëŒ€ì‘ ì¸¡ë©´:**

ìš°ì„ ìˆœìœ„í™” ì „ëµ:

| Priority | Condition | Action | SLA |
|----------|-----------|--------|-----|
| **P1-Critical** | State transition invalid + High-risk process | Immediate isolation | <5min |
| **P2-High** | Sketch outlier (distance > 2Ïƒ) | Analyst review | <1hr |
| **P3-Medium** | Sketch outlier (distance > 1.5Ïƒ) | Queue for investigation | <24hr |

**ë¶„ì„ ì¸¡ë©´:**

íŒ¨í„´ ì¸ì‚¬ì´íŠ¸: UNICORNì´ ë°œê²¬í•œ APT íŒ¨í„´ (supply chainì˜ subtle variation, stealthy exfiltrationì˜ daily unusual network spike)

Ground Truth ë¬¸ì œ: APT evaluationì˜ ê·¼ë³¸ì  ì–´ë ¤ì›€ - ì‹¤ì œ í™˜ê²½ì—ì„œ "benign"ì´ë¼ ê°€ì •í•œ ë°ì´í„°ì— ì´ë¯¸ APTê°€ ìˆ¨ì–´ìˆì„ ìˆ˜ ìˆìŒ

---

## Day 4 â€“ Research Limitations and Scholarly Impact
*(UNICORNì˜ í•œê³„ì™€ provenance ê¸°ë°˜ íƒì§€ì˜ ë°œì „)*

### 1. ì—°êµ¬ì˜ í•œê³„ì 

#### A. Parameter Sensitivity and Tuning Overhead

**ë¬¸ì œ:**

UNICORNì€ ì—¬ëŸ¬ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ì˜ì¡´:
- R (hop count): 1-7 ë²”ìœ„, ì„±ëŠ¥ì— í° ì˜í–¥
- |S| (sketch size): 500-5000, memory-accuracy trade-off
- Î» (decay factor): 0.990-0.999, forgetting rate
- Î¸ (clustering threshold): Cluster ê°œìˆ˜ ê²°ì •

ê° í™˜ê²½ë§ˆë‹¤ optimal parameterê°€ ë‹¤ë¦„. ë…¼ë¬¸ì—ì„œëŠ” OpenTunerë¡œ ìë™ tuningí–ˆì§€ë§Œ grid search ë¹„ìš©ì´ í¬ê³ , ìƒˆë¡œìš´ í™˜ê²½ë§ˆë‹¤ re-tuning í•„ìš”.

**í•´ê²° ë°©ì•ˆ:**

1. **Transfer learning**: ìœ ì‚¬ í™˜ê²½ì˜ parameterë¥¼ starting pointë¡œ ì‚¬ìš©
2. **Adaptive parameter selection**: Runtime metricìœ¼ë¡œ ìë™ ì¡°ì •
3. **Default configuration**: ë…¼ë¬¸ì˜ ê¶Œì¥ê°’ (R=3, |S|=2000, Î»=0.998)ì„ baselineìœ¼ë¡œ

#### B. Ground Truth and Labeling Challenge

**ë¬¸ì œ:**

APT í‰ê°€ì˜ ê·¼ë³¸ì  ì–´ë ¤ì›€:
1. Training dataê°€ ì •ë§ cleaní•œê°€? APTëŠ” ì´ë¯¸ ìˆ˜ê°œì›” ì „ ì¹¨íˆ¬í–ˆì„ ìˆ˜ ìˆìŒ
2. Detectionì˜ ì™„ì „ì„±: DARPAëŠ” red team ê³µê²©ë§Œ labeled, ë‹¤ë¥¸ ìˆ¨ì–´ìˆëŠ” ê³µê²©ì€?
3. FP vs TPì˜ ì• ë§¤í•¨: "FP"ë¡œ ë¶„ë¥˜í•œ ê²ƒ ì¤‘ ì¼ë¶€ê°€ ì‹¤ì œ ê³µê²©ì¼ ìˆ˜ ìˆìŒ

**í•´ê²° ë°©ì•ˆ:**

1. **Honeypot-based baseline**: ê²©ë¦¬ëœ í™˜ê²½ì—ì„œ clean baseline í™•ë³´
2. **Multi-stage validation**: UNICORN alert â†’ Threat intel cross-check â†’ Analyst review
3. **Conservative labeling**: "Suspicious but unconfirmed"ë¥¼ ë³„ë„ ì¹´í…Œê³ ë¦¬ë¡œ

#### C. Fileless and LOLBAS Attacks

**ë¬¸ì œ:**

UNICORNì€ provenance graphì— ì˜ì¡´í•˜ëŠ”ë°, ì¼ë¶€ ê³µê²©ì€ í”ì ì´ ì ìŒ:

1. **Fileless malware**: Memory-only execution (reflective DLL injection)
2. **Living-off-the-land binaries**: PowerShell, wmic, certutil ë“± ì •ìƒ ë„êµ¬ ì•…ìš©
3. **Kernel-level rootkits**: Provenance ìˆ˜ì§‘ ìì²´ë¥¼ ìš°íšŒ

**í•´ê²° ë°©ì•ˆ:**

1. **Behavioral context enrichment**: ëˆ„ê°€, ì–¸ì œ, ë¬´ì—‡ì„ ì‹¤í–‰í–ˆëŠ”ì§€ ì¶”ê°€ context
2. **Memory forensics í†µí•©**: Provenance ì™¸ì— periodic memory scan
3. **Hybrid approach**: UNICORN + YARA rules

#### D. Computational Scalability

**ë¬¸ì œ:**

ë…¼ë¬¸ì˜ evaluationì€ ìˆ˜ë°± host ê·œëª¨. í•˜ì§€ë§Œ enterpriseëŠ” ìˆ˜ë§Œ-ìˆ˜ì‹­ë§Œ endpoints.

**í•´ê²° ë°©ì•ˆ:**

1. **Hierarchical architecture**: Endpoint â†’ Regional aggregator â†’ Central SOC
2. **Edge computing**: Endpointì—ì„œ sketch ìƒì„±, ì¤‘ì•™ì—ëŠ” sketchë§Œ ì „ì†¡
3. **Distributed clustering**: Apache Spark ê¸°ë°˜ parallel processing

### 2. í›„ì† ì—°êµ¬ ë™í–¥

#### A. ì¸ìš© ìˆ˜ì™€ ì˜í–¥ë ¥

- ë°œí‘œ: 2020ë…„ NDSS
- í˜„ì¬ ì¸ìš© ìˆ˜: ~310íšŒ (ì—°í‰ê·  ~62íšŒ)
- Provenance ê¸°ë°˜ APT íƒì§€ì˜ ì£¼ìš” referenceë¡œ ìë¦¬ì¡ìŒ

#### B. ì—°êµ¬ íŠ¸ë Œë“œì˜ ë³€í™”

```
[2015-2017] Rule-based provenance (Holmes, Poirot)
    â†“
[2017-2019] ML-based anomaly (StreamSpot)
    â†“
[2020] UNICORN (Graph sketching + Evolutionary modeling)
    â†“
[2021-í˜„ì¬] Advanced provenance ML (Deep learning, GNN, Transformer)
```

#### C. ì£¼ìš” í›„ì† ì—°êµ¬

| ì—°êµ¬ | ì—°ë„ | í•µì‹¬ ê¸°ì—¬ |
|------|------|-----------|
| **TBDetector** | 2021 | Transformer with self-attention for long-term context |
| **PROGRAPHE** | 2022 | Graph Neural Network on provenance |
| **TFLAG** | 2023 | Temporal GNN + deviation network |
| **PROVNINJA** | 2022 | Adversarial attack on provenance detectors (UNICORN detection 100% â†’ 35%) |
| **MirGuard** | 2023 | Robustness against graph manipulation |
| **NODLINK** | 2024 | Online fine-grained APT across hosts |

ê°œì„ ì : UNICORNì˜ hand-crafted histogram â†’ learnable embedding, R-hop exploration â†’ attention mechanism, Fixed sketch size â†’ dynamic representation

Trade-off: Explainability ê°ì†Œ, Training ë¹„ìš© ì¦ê°€, Parameter tuning ë” ë³µì¡

### 3. ì‹¤ë¬´ ì˜í–¥

#### A. ì‚°ì—… í‘œì¤€í™”

**UNICORN ì´í›„:**

- DARPA Transparent Computing Programì—ì„œ provenance ìˆ˜ì§‘ í‘œì¤€í™”
- Operating System ì§€ì›: Linux eBPF, Windows ETW, macOS Endpoint Security
- Provenance ê°œë…ì´ EDR/XDRì˜ í•µì‹¬ ê¸°ëŠ¥ìœ¼ë¡œ

#### B. ì£¼ìš” ë²¤ë” ì±„íƒ

| ë²¤ë” | ê¸°ìˆ  | UNICORN ì˜í–¥ |
|------|------|-------------|
| **CrowdStrike Falcon** | Indicator of Attack (IoA) graph | Causal graph ê¸°ë°˜ íƒì§€, R-hop context |
| **Microsoft Defender ATP** | Advanced Hunting with KQL | Provenance query, multi-hop relationship |
| **SentinelOne** | Storyline behavioral AI | Process treeë¥¼ graphë¡œ í‘œí˜„, anomaly detection |

#### C. ì˜¤í”ˆì†ŒìŠ¤/ì»¤ë®¤ë‹ˆí‹° ì˜í–¥

- **CamFlow**: UNICORN ì €ì ì£¼ë„, Linux kernel provenance capture
- **SPADE**: Multi-platform provenance ìˆ˜ì§‘ í”„ë ˆì„ì›Œí¬
- **StreamSpot**: UNICORN baseline, communityê°€ ì¬í˜„ ì‹¤í—˜ ìˆ˜í–‰

### 4. SOC ê´€ì  ì¸ì‚¬ì´íŠ¸

**í•œê³„ë¥¼ ì¸ì‹í•œ ì‹¤ë¬´ ì ìš© ì „ëµ:**

ì „ëµ 1: Defense-in-Depth (L1 signature-based â†’ L2 UNICORN anomaly â†’ L3 analyst review â†’ L4 threat hunting)

ì „ëµ 2: Hybrid Supervised + Unsupervised (Known APT TTP rule + UNICORN unsupervised + correlation)

ì „ëµ 3: Continuous Model Validation and Update (ì›”ê°„ ì¬í•™ìŠµ ì‚¬ì´í´)

**ë„ì… ë¡œë“œë§µ:**

- **Short-term (1-3ê°œì›”)**: PoC (pilot hosts, baseline training, parameter tuning)
- **Mid-term (3-6ê°œì›”)**: Production rollout (critical servers, SOAR integration)
- **Long-term (6-12ê°œì›”)**: Enterprise scale (all endpoints, distributed architecture)

---

## Day 5 â€“ Conclusions and Practical Implications
*(SOC ì‹¤ë¬´ì— UNICORN ì ìš©í•˜ê¸°)*

### 1. 5ì¼ê°„ í•™ìŠµ ì—¬ì • ì¢…í•©

**Day 1:** APT íƒì§€ì˜ ê·¼ë³¸ ë¬¸ì œ â†’ Provenance graph ê¸°ë°˜ ì ‘ê·¼ì˜ í•„ìš”ì„±

**Day 2:** UNICORNì˜ ì„¤ê³„ ì² í•™ (Graph sketching + Evolutionary modeling) â†’ Long-term, space-efficient, robust

**Day 3:** ì‹¤ì¦ì  ê²€ì¦ (DARPA 100% detection, StreamSpot +24% precision) â†’ R=3ì˜ ì¤‘ìš”ì„±

**Day 4:** í•œê³„ì™€ ë°œì „ (Parameter tuning, fileless attack) â†’ í›„ì† ì—°êµ¬ â†’ ì‚°ì—… í‘œì¤€ìœ¼ë¡œ

**Day 5:** ì‹¤ë¬´ í†µí•© - ì–´ë–»ê²Œ ì‹¤ì œ SOCì— ì ìš©í•  ê²ƒì¸ê°€?

### 2. ì´ë¡ ì  ê¸°ì—¬ ì •ë¦¬

**í•™ìˆ ì  ì˜ì˜:**

1. Graph Sketching for APT Detection (long-running provenanceë¥¼ ê³ ì • í¬ê¸°ë¡œ ì••ì¶•)
2. Evolutionary Modeling (concept drift ëŒ€ì‘ + model poisoning ë°©ì§€)
3. APT-Specific Design Principles (L1-L4)

**íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜:**

Before: APT detection = Signature matching, Provenance = Forensics, Anomaly = Static baseline

After: APT detection = Unsupervised graph anomaly, Provenance = Real-time monitoring, Anomaly = Evolutionary model

### 3. SOC ì‹¤ë¬´ ì ìš© ì „ëµ

#### A. íƒì§€ ì—­ëŸ‰ ê°•í™”

**ì‹œë‚˜ë¦¬ì˜¤ 1: Supply Chain Attack**

íƒì§€ ë£°: Installer processì˜ R=3 neighborhood ë¶„ì„ â†’ unexpected child process ë°œê²¬

ì„ê³„ê°’: Distance > 0.5 (anomalous)

ìë™ ëŒ€ì‘: Process suspend â†’ memory snapshot â†’ network block

ê¸°ëŒ€ íš¨ê³¼: MTTD ìˆ˜ì¼ â†’ ìˆ˜ë¶„, MTTR ìˆ˜ì‹œê°„ â†’ ìˆ˜ë¶„, FP <5%

**ì‹œë‚˜ë¦¬ì˜¤ 2: Data Exfiltration**

íƒì§€ ë£°: Sensitive file read â†’ network upload correlation ë¶„ì„

ì„ê³„ê°’: Volume >10MB/1hr, destination not in whitelist

ìë™ ëŒ€ì‘: Block connection â†’ isolate host â†’ notify team

**ì‹œë‚˜ë¦¬ì˜¤ 3: Lateral Movement**

íƒì§€ ë£°: Inter-host connection (SSH, RDP) â†’ target host activity ë¶„ì„

MITRE ATT&CK: T1021, T1003, T1082

ìë™ ëŒ€ì‘: Alert â†’ increase logging â†’ containment

#### B. ëŒ€ì‘ ì—­ëŸ‰ ê°•í™”

**ìš°ì„ ìˆœìœ„í™”:**

| Priority | Condition | SLA | Owner |
|----------|-----------|-----|-------|
| **P1-Critical** | State transition invalid + High-risk TTP | <5min | L3 Senior |
| **P2-High** | Sketch distance > 2Ïƒ + Medium-risk TTP | <30min | L2 |
| **P3-Medium** | Sketch distance > 1.5Ïƒ | <2hr | L1 |
| **P4-Low** | Marginal anomaly | <24hr | Auto |

**í”Œë ˆì´ë¶:**

Data Exfiltration (P1): [AUTO] Block network + Isolate + Capture | [MANUAL] Assess + Hunt

Lateral Movement (P2): [AUTO] Alert + Log | [MANUAL] Map path + Contain + Revoke

Supply Chain (P2): [AUTO] Suspend + Quarantine | [MANUAL] Reverse engineer + Notify vendor

**í‹°ì¼“ ì˜ˆì‹œ:**
```
ğŸš¨ UNICORN APT ALERT
ì œëª©: [P1-CRITICAL] Credential Dumping - DC01
ì‹¬ê°ë„: Critical
ë‹´ë‹¹ì: L3-Senior-Team
SLA: <5 minutes

â”â”â” íƒì§€ ì •ë³´ â”â”â”
Method: UNICORN Evolutionary Model
Sketch Distance: 2.34Ïƒ
State Transition: INVALID

â”â”â” ê³µê²© í–‰ìœ„ â”â”â”
Host: DC01 (Domain Controller)
Process: powershell.exe â†’ lsass.exe memory â†’ C:\temp\c.txt â†’ 192.0.2.123

â”â”â” MITRE ATT&CK â”â”â”
â€¢ T1003.001 - LSASS Memory
â€¢ T1059.001 - PowerShell

â”â”â” ìë™ ëŒ€ì‘ (ì™„ë£Œ) â”â”â”
âœ… Network blocked
âœ… Host isolated
âœ… Memory captured

â”â”â” ê¶Œì¥ ì¡°ì¹˜ â”â”â”
1. [URGENT] Review memory dump
2. [URGENT] Reset domain passwords
3. [URGENT] Hunt similar activity
```

#### C. ë¶„ì„ ì—­ëŸ‰ ê°•í™”

**Threat Hunting:**

Hidden C2 Communication:
```sql
SELECT hostname, process, remote_ip, COUNT(*) as conn_count
FROM provenance_graph
WHERE timestamp > NOW() - INTERVAL '7 days'
  AND remote_ip NOT IN (SELECT ip FROM whitelist)
  AND protocol IN ('HTTPS', 'DNS')
  AND conn_count > 10
GROUP BY hostname, process, remote_ip;
```

**ROI ì¸¡ì •:**

ê²½ì˜ì§„ ë³´ê³ ì„œ:
```
UNICORN ë„ì… 6ê°œì›” ì„±ê³¼

í•µì‹¬ ì§€í‘œ:
- APT íƒì§€: 12ê±´ (+200%)
- ì¹¨í•´ ì°¨ë‹¨: 100%
- False Positive: 92% ê°ì†Œ
- MTTD: 47ì¼ â†’ 2.3ì¼ (95% ê°œì„ )

íˆ¬ì ëŒ€ë¹„ íš¨ê³¼:
- ë„ì… ë¹„ìš©: $500K
- ë°©ì§€í•œ í”¼í•´ì•¡: $8M
- ROI: 1,600%
```

### 4. í”„ë ˆì„ì›Œí¬/í‘œì¤€ ì—°ê³„

#### A. MITRE ATT&CK ë§¤í•‘

| UNICORN íƒì§€ | ATT&CK | íƒì§€ ë¡œì§ |
|-------------|--------|-----------|
| Credential Dumping | T1003.001 LSASS | Process â†’ read lsass memory |
| Data Exfiltration | T1041 Exfiltration | File read â†’ network upload |
| Lateral Movement | T1021 Remote Services | Unusual SSH/RDP connection |

#### B. NIST Cybersecurity Framework

| NIST | UNICORN í™œìš© | ì ìš© |
|------|-------------|------|
| Identify | Asset discovery | ì •ìƒ baseline í”„ë¡œíŒŒì¼ë§ |
| Protect | Proactive blocking | Supply chain ì„¤ì¹˜ ì „ ì°¨ë‹¨ |
| Detect | Real-time anomaly | APT ì¡°ê¸° ë°œê²¬ |
| Respond | Automated containment | P1 alert ì‹œ ìë™ ê²©ë¦¬ |
| Recover | Attack chain reconstruction | ì¹¨í•´ ë²”ìœ„ ì •í™•íˆ íŒŒì•… |

### 5. ì‹¤ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

#### A. ë„ì… ì „ ì¤€ë¹„

**ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­:**
- [ ] Linux kernel 4.4+ (eBPF) ë˜ëŠ” CamFlow
- [ ] CPU: 4 cores+, RAM: 16GB+, Disk: 1TB+
- [ ] Network: 10Gbps+

**ë°ì´í„° í’ˆì§ˆ:**
- [ ] Audit logging í™œì„±í™”
- [ ] Provenance completeness ê²€ì¦
- [ ] Baseline period í™•ì • (ìµœì†Œ 30ì¼)

**ì¡°ì§ ì¤€ë¹„ë„:**
- [ ] SOC team training
- [ ] Stakeholder alignment
- [ ] Budget approval

#### B. Phase 1: íŒŒì¼ëŸ¿ (Week 1-8)

Week 1-2: Infrastructure setup
Week 3-6: Baseline training
Week 7-10: Pilot detection
Week 11-12: Evaluation & Decision

#### C. Phase 2: í™•ì¥ (Week 9-24)

Week 13-16: Critical servers (100-200ëŒ€)
Week 17-20: SOAR integration
Week 21-24: Tuning and optimization

#### D. Phase 3: ìµœì í™” (Week 25-52)

Week 25-36: Full enterprise deployment
Week 37-48: Advanced capabilities
Week 49-52: Continuous improvement

### 6. 5ì¼ê°„ ë¦¬ë·° ì¢…í•©

| Day | ì£¼ì œ | í•µì‹¬ í•™ìŠµ | ì‹¤ë¬´ ì ìš© |
|-----|------|-----------|-----------|
| **Day 1** | APT íƒì§€ ê·¼ë³¸ ë¬¸ì œ | Provenance graph í•„ìš” | EDR/XDR ë°±ì—”ë“œ |
| **Day 2** | UNICORN ì„¤ê³„ | Graph sketching + Evolutionary | Unsupervised learning |
| **Day 3** | ì‹¤ì¦ì  ê²€ì¦ | DARPA 100%, +24% precision | R=3 í•„ìˆ˜, real-time ê°€ëŠ¥ |
| **Day 4** | í•œê³„ì™€ ë°œì „ | Parameter tuning, fileless í•œê³„ | Defense-in-depth |
| **Day 5** | ì‹¤ë¬´ í†µí•© | Supply chain, exfiltration íƒì§€ | ATT&CK ë§¤í•‘, SOAR |

### 7. ìµœì¢… ê°œì¸ ì¸ì‚¬ì´íŠ¸

#### A. ì´ ë…¼ë¬¸ì´ ë‚˜ì˜ SOC ì—­ëŸ‰ì— ê¸°ì—¬í•œ ì 

**í•µì‹¬ ë°°ì›€ 1: APT íƒì§€ëŠ” Contextê°€ ì „ë¶€**

UNICORNì˜ R-hop explorationì´ ì¦ëª…: ë‹¨ìˆœ local patternì´ ì•„ë‹ˆë¼ wider causal contextë¥¼ ë³´ëŠ” ê²ƒì´ í•µì‹¬. SOC analystê°€ ìˆ˜ë™ìœ¼ë¡œ í•˜ë˜ "ê³µê²© ì—°ê²°ê³ ë¦¬ ì°¾ê¸°"ë¥¼ ìë™í™”.

**í•µì‹¬ ë°°ì›€ 2: Evolutionary Modelingì€ í˜„ì‹¤ì  í•„ì—°**

ì‹œìŠ¤í…œì€ ë³€í•œë‹¤. Static modelì€ ë¹ ë¥´ê²Œ obsolete. Evolutionary modelì€ ì ì§„ì  ë³€í™”ëŠ” í¡ìˆ˜í•˜ë©´ì„œ ê¸‰ê²©í•œ anomaly íƒì§€.

**í•µì‹¬ ë°°ì›€ 3: ì™„ë²½í•œ ì†”ë£¨ì…˜ì€ ì—†ë‹¤**

UNICORNë„ í•œê³„ê°€ ìˆë‹¤ (fileless, LOLBAS, parameter tuning). ì‹¤ë¬´ì—ì„œëŠ” multi-layer defenseê°€ ë‹µ.

**í•µì‹¬ ë°°ì›€ 4: í•™ìˆ  ì—°êµ¬ê°€ ì‚°ì—…ì„ ë°”ê¾¼ë‹¤**

UNICORN ë°œí‘œ í›„ 5ë…„ ë§Œì— provenance ê¸°ë°˜ íƒì§€ê°€ EDR/XDR í‘œì¤€ì´ ë¨.

**í•µì‹¬ ë°°ì›€ 5: ì´ë¡ ê³¼ ì‹¤ë¬´ì˜ ê· í˜•**

ë…¼ë¬¸ì˜ "100% detection"ê³¼ ì‹¤ì œ ë°°í¬ëŠ” ë‹¤ë¥´ë‹¤. í•˜ì§€ë§Œ ì´ë¡ ì  ê¸°ë°˜ ì—†ì´ ê²½í—˜ë§Œìœ¼ë¡œëŠ” í•œê³„. ê· í˜•ì´ í•„ìš”.

#### B. [4í¸ì˜ ë…¼ë¬¸]ê³¼ì˜ ë¹„êµ ì¢…í•©

| ë…¼ë¬¸ | í•µì‹¬ ì•„ì´ë””ì–´ | ê°•ì  | ì•½ì  | ì ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|--------------|------|------|---------------|
| **DeepLog** | Deep learning on log sequence | Zero-day íƒì§€ | Single-host only | ë‹¨ì¼ ì‹œìŠ¤í…œ anomaly |
| **Lou et al.** | Invariants mining | Explainable rules | Rule extraction ë¹„ìš© | Stable system |
| **Beehive** | Network workflow graph | Enterprise-wide view | Network-levelë§Œ | Network intrusion |
| **UNICORN** | Provenance graph sketching | System-level causality | Parameter tuning | APT detection |

í†µí•© ì „ëµ: L1 DeepLog (endpoint) â†’ L2 Beehive (network) â†’ L3 UNICORN (system APT) â†’ L4 Lou et al. (validation)

#### C. ë©´ì ‘ ëŒ€ë¹„ í•µì‹¬ ë©”ì‹œì§€ (1ë¶„)

"UNICORNì€ APT íƒì§€ì˜ í•µì‹¬ ë¬¸ì œë¥¼ í•´ê²°í•œ ì—°êµ¬ì…ë‹ˆë‹¤.

ì²«ì§¸, Low-and-slow APTëŠ” ê¸°ì¡´ íƒì§€ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤. UNICORNì€ provenance graphì™€ evolutionary modelingìœ¼ë¡œ ìˆ˜ê°œì›” ê³µê²©ë„ íƒì§€í•©ë‹ˆë‹¤.

ë‘˜ì§¸, Graph sketchingìœ¼ë¡œ TB ê·œëª¨ë¥¼ 200MBë¡œ ì‹¤ì‹œê°„ ë¶„ì„. DARPAì—ì„œ 100% íƒì§€ìœ¨ ë‹¬ì„±.

ì…‹ì§¸, 2020ë…„ ë°œí‘œ í›„ CrowdStrike, Microsoft ë“±ì´ provenance ê¸°ë°˜ íƒì§€ë¥¼ ì±„íƒí•˜ëŠ” ê³„ê¸°ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤.

ê²°ë¡ ì ìœ¼ë¡œ, ì´ ë…¼ë¬¸ì„ í†µí•´ APT íƒì§€ì—ì„œ contextì™€ causalityì˜ ì¤‘ìš”ì„±ì„ ë°°ì› ê³ , ì‹¤ë¬´ì—ì„œ UNICORNì„ SIEMì˜ advanced detection engineìœ¼ë¡œ í†µí•©í•˜ì—¬ supply chain attack, credential dumping, lateral movementë¥¼ ì¡°ê¸° ì°¨ë‹¨í•˜ëŠ” ì „ëµì„ ìˆ˜ë¦½í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤."

#### D. ë‹¤ìŒ í•™ìŠµ ë°©í–¥

**ìš°ì„ ìˆœìœ„ 1: Deep Learning ê¸°ë°˜ Provenance ë¶„ì„**
- TBDetector (Transformer), PROGRAPHE (GNN)
- í•™ìŠµ ëª©í‘œ: UNICORNì˜ hand-crafted featureë¥¼ deep learningìœ¼ë¡œ ëŒ€ì²´

**ìš°ì„ ìˆœìœ„ 2: Adversarial Robustness**
- PROVNINJA, MirGuard
- í•™ìŠµ ëª©í‘œ: ê³µê²©ìê°€ UNICORN ìš°íšŒí•˜ëŠ” ë°©ë²•ê³¼ ë°©ì–´

**ìš°ì„ ìˆœìœ„ 3: Cross-Host Attack Campaign**
- NODLINK, Cyber Persistence Detector
- í•™ìŠµ ëª©í‘œ: Multi-host correlation ê¸°ë²•

**ìš°ì„ ìˆœìœ„ 4: Explainable AI for Security**
- Provenance graph visualization
- í•™ìŠµ ëª©í‘œ: Black-box detector ê²°ê³¼ë¥¼ analystê°€ ì´í•´

**ì¥ê¸° ëª©í‘œ:**
- 6ê°œì›” í›„: UNICORN ê¸°ë°˜ APT íƒì§€ ì‹œìŠ¤í…œ PoC êµ¬í˜„
- 1ë…„ í›„: ìì²´ íƒì§€ ë£° ê°œë°œ
- 2ë…„ í›„: Provenance ê¸°ë°˜ íƒì§€ ì „ë¬¸ê°€ë¡œ ì»¨í¼ëŸ°ìŠ¤ ë°œí‘œ

### 8. ìµœì¢… ê²°ë¡ 

#### A. UNICORNì˜ ìœ ì‚°

2020ë…„ ë…¼ë¬¸ í•˜ë‚˜ê°€ provenance ê¸°ë°˜ APT íƒì§€ë¥¼ í•™ìˆ  ì—°êµ¬ì—ì„œ ì‚°ì—… í‘œì¤€ìœ¼ë¡œ ëŒì–´ì˜¬ë¦¼. 2025ë…„ í˜„ì¬ë„ DARPA TC datasetì˜ baseline detectorë¡œ ì‚¬ìš©. í›„ì† ì—°êµ¬ë“¤ì˜ ë¹„êµ ëŒ€ìƒ.

#### B. SOC ë¶„ì„ê°€ë¡œì„œì˜ ë‹¤ì§

"ì•Œê³  ìˆë‹¤"ì—ì„œ "í•  ìˆ˜ ìˆë‹¤"ë¡œ

Phase 1 (ì™„ë£Œ): ë…¼ë¬¸ ì´í•´ (DeepLog, Lou et al., Beehive, UNICORN)
Phase 2 (ì§„í–‰ ì¤‘): ì‹¤ìŠµ (CamFlow + Pythonìœ¼ë¡œ PoC)
Phase 3 (ë‹¤ìŒ): ì‹¤ë¬´ ì ìš© (SOC í™˜ê²½ì— ë°°í¬)
Phase 4 (ëª©í‘œ): ê¸°ì—¬ (ì˜¤í”ˆì†ŒìŠ¤, ì»¨í¼ëŸ°ìŠ¤)

ë‹¨ìˆœí•œ "ë„êµ¬ ì‚¬ìš©ì"ê°€ ì•„ë‹Œ ì›ë¦¬ë¥¼ ì´í•´í•˜ëŠ” ì „ë¬¸ê°€, ì‹¤ë¬´ ì ìš© ì „ëµì„ ì„¸ìš°ëŠ” ì„¤ê³„ì, ìƒˆë¡œìš´ ë°©ë²•ì„ ë§Œë“œëŠ” ì—°êµ¬ì.

**ë‹¤ìŒ ë…¼ë¬¸ì—ì„œ ë˜ ë§Œë‚˜ìš”!**

---

## References

[1] Han, X., Pasquier, T., Bates, A., Mickens, J., & Seltzer, M. (2020). UNICORN: Runtime Provenance-Based Detector for Advanced Persistent Threats. *Network and Distributed System Security Symposium (NDSS)*, pp. 1-18. https://doi.org/10.14722/ndss.2020.24046

[2] Manzoor, E., Milajerdi, S. M., & Akoglu, L. (2016). Fast Memory-efficient Anomaly Detection in Streaming Heterogeneous Graphs. *ACM SIGKDD*.

[3] Milajerdi, S. M., Gjomemo, R., Eshete, B., Sekar, R., & Venkatakrishnan, V. (2019). HOLMES: Real-time APT Detection through Correlation of Suspicious Information Flows. *IEEE S&P*.

---

## Tags
`#SOC` `#APTDetection` `#ProvenanceGraphs` `#AnomalyDetection` `#GraphSketching` `#EvolutionaryModeling` `#UNICORN` `#NDSS2020` `#SKShieldusRookies`