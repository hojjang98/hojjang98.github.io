---
layout: post
title: "🍱 Models Stop, Lessons Don’t – Finalizing the Food Classifier"
date: 2025-05-18
---

Today marks the final chapter of my first full computer vision project.  
After dozens of experiments, hundreds of crawled images, and countless hours of training — I’m calling it.

Not because I’ve reached the perfect model.  
But because I’ve reached my **deadline** — and that matters too.

---

## 🔄 What I Did (Recap)

Over the past week, I tried to stretch this project in every direction:

- 📸 Crawled **200+ images per class** for 36 food categories  
- 🔍 Improved keyword specificity (`"fruit apple"` vs. `"food"`)  
- 🧹 Filtered corrupted or low-quality images  
- 🧪 Trained and tuned **MobileNetV2** with transfer learning  
- 🛠️ Applied techniques like:
  - EarlyStopping
  - ReduceLROnPlateau
  - ModelCheckpoint
  - Basic class_weight balancing

And yes — I watched accuracy climb from **14% → 61%**.  
But more importantly, I **watched myself improve**.

---

## 💭 What I Learned

This project wasn't about getting 95% accuracy.  
It was about **building the pipeline from scratch**, and discovering what really moves the needle:

- 🧠 **Data is everything**: Doubling the dataset often gave more gain than changing the model  
- 🧼 **Preprocessing matters**: Cleaning data beat fancy architectures  
- ⚖️ **Ethics isn’t optional**: I consciously avoided redistributing images, and made sure to disclaim copyright concerns  
- 🎯 **Deadlines are real**: I chose to **stop experiments early** — not because I ran out of ideas, but because the goal was *completeness*, not perfection

I now understand the full CV process better:  
From crawling and cleaning → to training and tuning → to reporting and reflecting.

---

## 📌 If I Had More Time...

- Try `EfficientNetB0` or `ResNet50`  
- Fine-tune pretrained weights  
- Apply Grad-CAM for interpretability  
- Build a Streamlit demo for the model  
- Use Test-Time Augmentation or mixup

But again, *experimentation never ends*.  
This project does.

---

## ✅ Final Metrics

- **Accuracy**: 61%  
- **Macro F1-score**: 0.60  
- Best performing classes: `banana`, `pineapple`, `kiwi`  
- Worst: `capsicum`, `apple`, `corn`

Model: **MobileNetV2 (frozen base)** + custom dense layers  
Optimizer: **Adam**, learning rate schedule enabled

---

## 🌱 Final Reflection

> You don’t have to finish *everything*.  
> You just have to finish **something** — and learn from it.

This was my first real dive into computer vision.  
I’m walking away not just with a model, but with a mindset.

And that’s worth more than accuracy.

